{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the numpy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printoptions helps us improve the way we display the output on the screen \n",
    "\n",
    "np.set_printoptions(suppress = True, linewidth = 100, precision = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset using np.genfromtxt function (to avoid errors if there is missing values) & display it\n",
    "\n",
    "raw_data_np = np.genfromtxt(\"loan-data.csv\", \n",
    "                            delimiter = \";\", \n",
    "                            skip_header = 1, \n",
    "                            autostrip = True)\n",
    "raw_data_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Checking for Incomplete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See how many missing values we have (np.isnan() provides an array of True (it is a missing value) or False, \n",
    "#with the sum() function, the number of 'True' will be summed\n",
    "\n",
    "np.isnan(raw_data_np).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to temporary fill the missing entries of the dataset (temporary_fill)\n",
    "# It will later be raplaced with the temporary_mean variable (holds the means for every column)\n",
    "\n",
    "temporary_fill = np.nanmax(raw_data_np).round(2) + 1\n",
    "temporary_mean = np.nanmean(raw_data_np, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Store the max and the min in an array,  that will be useful later on\n",
    "\n",
    "temporary_stats = np.array([np.nanmin(raw_data_np, axis = 0), \n",
    "                            temporary_mean, \n",
    "                            np.nanmax(raw_data_np, axis = 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy does not like us storing diffferent data types in the same array since it limits what we can do with the dataset. We will thus split the data set into two datasets: one containing the numerical values, and one containing the string values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting the Dataset & Reimporting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the columns with strings values (= mean is nan)\n",
    "# np.argwhere() will return the index of the column in the original dataset\n",
    "column_strings = np.argwhere(np.isnan(temporary_mean)).squeeze()\n",
    "column_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the index of the columns with  numeric values\n",
    "column_numeric = np.argwhere(np.isnan(temporary_mean) == False).squeeze()\n",
    "column_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the string data set \n",
    "loan_data_strings = np.genfromtxt(\"loan-data.csv\",\n",
    "                                  delimiter = \";\",\n",
    "                                  skip_header = 1,\n",
    "                                  autostrip = True,\n",
    "                                  usecols = column_strings,\n",
    "                                  dtype = str)\n",
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the numeric data set and defining the missing values as temporary_fill\n",
    "loan_data_numeric = np.genfromtxt(\"loan-data.csv\",\n",
    "                                  delimiter = \";\",\n",
    "                                  skip_header = 1,\n",
    "                                  autostrip = True,\n",
    "                                  usecols = column_numeric,\n",
    "                                  filling_values = temporary_fill)\n",
    "loan_data_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the header information\n",
    "#skip_footer = raw_data_np.shape[0] : will not import all rows after the header\n",
    "header_full = np.genfromtxt(\"loan-data.csv\",\n",
    "                            delimiter = \";\",\n",
    "                            skip_footer = raw_data_np.shape[0],\n",
    "                            autostrip = True,\n",
    "                            dtype = str)\n",
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the header of each data type in a seperate variable using their indexes\n",
    "header_strings, header_numeric = header_full[column_strings], header_full[column_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header_numeric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header = checkpoint_header, data = checkpoint_data)\n",
    "    checkpoint_variable = np.load(file_name + \".npz\")\n",
    "    return(checkpoint_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_test = checkpoint('checkpoint-test', \n",
    "                             header_strings, \n",
    "                             loan_data_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Manipulating String Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Issue Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the first header to a more explicitname \n",
    "header_strings[0] = \"issue_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise the data in the issue date column (Format: Month - Year)\n",
    "loan_data_strings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All loans are from the year -15 --> Excess data\n",
    "np.unique(loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stripping the \"-15\" from the column and overwritting the given column \n",
    "loan_data_strings[:,0] = np.chararray.strip(loan_data_strings[:,0], \"-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stocking the months as numerical values (less memory space used & order) using \n",
    "#a loop and the np.where() function \n",
    "for i in range(13):\n",
    "        loan_data_strings[:,0] = np.where(loan_data_strings[:,0] == months[i],\n",
    "                                          i,\n",
    "                                          loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We transformed this string column into a numerical one.\n",
    "np.unique(loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_strings[1] = \"loan_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,1]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Good loan status (not defaulted): \"Fully paid\", \"Current\", \"Issued\", \"In grace period\", \"Late (16-30 days)\" = 1 \n",
    "\n",
    "2. Bad loan status (defaulted): \"Charged off\", \"Default\", \"Late (31-120 days)\" ,missing values = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the loan status considered as bad in a separate array\n",
    "loan_status_bad = np.array(['Charged Off', 'Default', 'Late(31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.isin(): checks if the elements in  interval 2 are in interval 1\n",
    "#np.where(): replace the bad loan status with the number 0, otherwise (good loan status) 1.\n",
    "loan_data_strings[:,1]= np.where(np.isin(loan_data_strings[:,1], \n",
    "                                         loan_status_bad),\n",
    "                                 0,\n",
    "                                 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We created a dummy variable, which is what was asked from us.\n",
    "np.unique(loan_data_strings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_strings[2] = \"term_months\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,2]= np.chararray.strip(loan_data_strings[:,2], \" months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We assume the worst: Missing values = 60 month (long period in itself for a loan\n",
    "#to pay off, worst term we can potentially end up with)\n",
    "loan_data_strings[:,2] = np.where(loan_data_strings[:,2] == '', \n",
    "                                  '60',\n",
    "                                  loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,2])\n",
    "#As expected, we get only 36 and 60 \n",
    "#when we only have two possible numerical outcomes for a given column,\n",
    "#this immediately rings a bell that we could just use one in zero instead.\n",
    "#always ask the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Grade and Subgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For every element in grade, there are 5 subelements in subgrade\n",
    "#The information that we obtain in the grade column can also be obtained in the \n",
    "#subgrade column.\n",
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 Filling Sub Grade & Deleting Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We assign the lowest, worst subgrade (5) to the missing values in the third column\n",
    "#when we have a grade for this value.\n",
    "for i in np.unique(loan_data_strings[:,3])[1:]:\n",
    "    loan_data_strings[:,4] = np.where((loan_data_strings[:,4] == '') & (loan_data_strings[:,3] == i),\n",
    "                                      i + '5',\n",
    "                                      loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#For the missing values for both grade and subgrade, we assume the worst\n",
    "#We will create a lower value than G5 \n",
    "loan_data_strings[:,4] = np.where((loan_data_strings[:,4] == ''),\n",
    "                                      \"H1\",\n",
    "                                      loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We cleaned the Subgrade column, we don't have any missing values anymore (H1 instead)\n",
    "np.unique(loan_data_strings[:,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove the grade (3) column (axis = 1)\n",
    "#since we have this information in the subgrade column\n",
    "loan_data_strings = np.delete(loan_data_strings,3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete this header of this column as well\n",
    "header_strings = np.delete(header_strings, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Converting Sub Grade into a Numerical Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constitute a dictionary with keys equal to the subgrade (string) and values equal \n",
    "#to a rank of trustworthiness (A1 = 1) \n",
    "keys = list(np.unique(loan_data_strings[:,3]))                         \n",
    "values = list(range(1, np.unique(loan_data_strings[:,3]).shape[0] + 1)) \n",
    "dict_sub_grade = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_sub_grade.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_sub_grade.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate for each subgrade and substitute each one with its associated \n",
    "#numerical value (Key)\n",
    "for i in np.unique(loan_data_strings[:,3]):\n",
    "        loan_data_strings[:,3] = np.where(loan_data_strings[:,3] == i, \n",
    "                                          dict_sub_grade[i],\n",
    "                                          loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##We transformed this string column into a numerical one.\n",
    "np.unique(loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Verification Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Good verification status (loan applications that include investor backing)= 1\n",
    "2. Bad verification status = \"Not verified\", '' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_status_bad = ['Not verified', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,4] = np.where(np.isin(loan_data_strings[:,4], verification_status_bad), \n",
    "                                  0, \n",
    "                                  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We transformed this string column into a numerical one.\n",
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the unique elements in the url (loan_id number)\n",
    "loan_data_strings[:,5]= np.chararray.strip(loan_data_strings[:,5], \n",
    "                                           \"https://www.lendingclub.com/browse/loanDetail.action?loan_id=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load_ID (string) = ID (float)\n",
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_numeric[:,0].astype(dtype= np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,5].astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Both arrays are identical\n",
    "np.array_equal(loan_data_numeric[:,0].astype(dtype= np.int32),loan_data_strings[:,5].astype(dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can get rid of the URL column since it odoes not hold any additional value.\n",
    "loan_data_strings = np.delete(loan_data_strings, 5, axis = 1)\n",
    "header_strings = np.delete(header_strings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 State Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_strings[5] = \"state_addresss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,5], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,5]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,5], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We sort the state name and count in ascending order\n",
    "states_names, states_count = np.unique(loan_data_strings[:,5], return_counts = True)\n",
    "states_count_sorted = np.argsort(-states_count)\n",
    "states_names[states_count_sorted], states_count[states_count_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,5] = np.where(loan_data_strings[:,5] =='', 0, loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_west = np.array(['WA', 'OR','CA','NV','ID','MT', 'WY','UT','CO', 'AZ','NM','HI','AK'])\n",
    "states_south = np.array(['TX','OK','AR','LA','MS','AL','TN','KY','FL','GA','SC','NC','VA','WV','MD','DE','DC'])\n",
    "states_midwest = np.array(['ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH'])\n",
    "states_east = np.array(['PA','NY','NJ','CT','MA','VT','NH','ME','RI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings[:,5] = np.where(np.isin(loan_data_strings[:,5], states_west), 1, loan_data_strings[:,5])\n",
    "loan_data_strings[:,5] = np.where(np.isin(loan_data_strings[:,5], states_south), 2, loan_data_strings[:,5])\n",
    "loan_data_strings[:,5] = np.where(np.isin(loan_data_strings[:,5], states_midwest), 3, loan_data_strings[:,5])\n",
    "loan_data_strings[:,5] = np.where(np.isin(loan_data_strings[:,5], states_east), 4, loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Converting String Column to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now, we converted each string data we have into numeric values stored as text, we now have to convert them to a numeric data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings = loan_data_strings.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Checkpoint 1: Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_strings= checkpoint(\"Checkpoint- Strings\", header_strings, loan_data_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_strings[\"header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_strings[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(checkpoint_strings[\"data\"], loan_data_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Manipulating Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values = check if any of the elements in the column is equal to temporary_fill\n",
    "temporary_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We must substitute the missing values with the worst possible values\n",
    "np.isnan(loan_data_numeric).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use the statistics that we stored in temporary_stats (min, max, mean)\n",
    "#We don't have any statstics in the string columns (string values)\n",
    "temporary_stats[:, column_numeric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isin(loan_data_numeric[:,0], temporary_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No missing values (normal since it is the ID column)\n",
    "np.isin(loan_data_numeric[:,0], temporary_fill).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Funded Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst case scenario = Minimum value (first row of the temporary_stats)\n",
    "loan_data_numeric[:,2] = np.where(loan_data_numeric[:,2] == temporary_fill, \n",
    "                                  temporary_stats[0, column_numeric[2]],\n",
    "                                  loan_data_numeric[:,2])\n",
    "loan_data_numeric[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Loaned Amount, Interest Rate, Total Payment, Installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We replace the temporary_fill with the maximum value (third row of the temporary_stats)\n",
    "for i in [1,3,4,5]: \n",
    "    loan_data_numeric[:,i] = np.where(loan_data_numeric[:,i] == temporary_fill, \n",
    "                                  temporary_stats[2, column_numeric[i]],\n",
    "                                  loan_data_numeric[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Currency Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 The Exchange Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filled out all missing values properly, we will now convert all the Dollar signes to Euros. To do this, we need the exchange rate between the 2 currencies at the time of the loan application\n",
    "\n",
    "EUR-USD.csv contains the average monthly exchange rates for 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In our case, we only care about the close daily exchange rate (adjusted closing prices), third column\n",
    "EUR_USD= np.genfromtxt(\"EUR-USD.csv\",\n",
    "                       delimiter= \",\", \n",
    "                       autostrip = True, \n",
    "                       skip_header = 1, \n",
    "                       usecols = 3)\n",
    "EUR_USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Months in which the loan was issued (0= missing values)\n",
    "loan_data_strings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substitute the month value with the exchange rate at that time \n",
    "exchange_rate = loan_data_strings[:,0]\n",
    "for i in range(1,13):\n",
    "    exchange_rate = np.where(exchange_rate == i,\n",
    "                             EUR_USD[i-1],\n",
    "                             exchange_rate)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substitute the missing values (= 0) with the mean of the array\n",
    "exchange_rate = np.where(exchange_rate == 0,\n",
    "                             np.mean(EUR_USD),\n",
    "                             exchange_rate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We need to reshape the exchange rate array, transform it into an array\n",
    "exchange_rate = np.reshape(exchange_rate, (10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We stack the exchange_rate array to the loan_data_numeric array = \n",
    "#we add a column to the dataset\n",
    "loan_data_numeric = np.hstack((loan_data_numeric, exchange_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric  = np.concatenate((header_numeric, np.array(['exchange_rate'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2 From USD to EUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dollar = np.array([1,2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_numeric[:, [columns_dollar]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We divide each column with a dollar value by the exchange rate to obtain the\n",
    "#value in eur , reshape it to obtain an array & stack it to the data set. \n",
    "for i in columns_dollar:\n",
    "    loan_data_numeric = np.hstack((loan_data_numeric, \n",
    "                                   np.reshape(loan_data_numeric[:,i] / loan_data_numeric[:,6], (10000,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have five new columns in the array.\n",
    "loan_data_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.3 Expanding the header with the five new columns created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_additional = np.array([column_name + '_EUR' for column_name in header_numeric[columns_dollar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric = np.concatenate((header_numeric, header_additional))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric[columns_dollar] = np.array([column_name + '_USD' for column_name in header_numeric[columns_dollar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each EUR column will follow its corresponding US column\n",
    "columns_index_order = [0,1,7,2,8,3,4,9,5,10,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric = header_numeric[columns_index_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric = loan_data_numeric[:,columns_index_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we have : \n",
    "1. Appropriately filled out any missing values\n",
    "2. Added exchange rates for each applicant (account)\n",
    "3. Created EUR versions of the 5 monetary values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Interest Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_numeric[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usually, it's better to have the interest rates between 0 and 1, we will thus\n",
    "#divide it by 100\n",
    "loan_data_numeric[:,5] = loan_data_numeric[:,5]/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Checkpoint 2: Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_numeric = checkpoint(\"Checkpoint-Numeric\", header_numeric, loan_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_numeric['header'], checkpoint_numeric['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Creating the \"Complete\" Dataset & Sorting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_strings['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_numeric['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((checkpoint_numeric['data'], checkpoint_strings['data'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data = np.hstack((checkpoint_numeric['data'], checkpoint_strings['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(loan_data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_full = np.concatenate((checkpoint_numeric['header'], checkpoint_strings['header']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to rearrange the entire dataset according to the values in the first column (ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(loan_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = loan_data[np.argsort(loan_data[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(loan_data[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Storing the New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = np.vstack((header_full, loan_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"loan-data-preprocessed.csv\", \n",
    "           loan_data, \n",
    "           fmt = \"%s\", \n",
    "           delimiter = \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
